}
# Validate 'var_types'
if (length(var_types) != (ncol(data) - 1)) {
stop("'var_types' must have length equal to the number of variables (columns minus the class label).")
}
# Determine the total number of classes after re-labeling
total_classes <- length(unique(data[, class_col_index]))
# Default 'nCore' if not specified: min(total_classes, detectCores()-1)
if (is.null(nCore)) {
nCore <- min(total_classes, max(1, parallel::detectCores() - 1))
}
# Split data into learning and test sets
if (learn_ratio < 1) {
split <- split_data(data, learn_ratio)
learn <- split$train
test <- split$test
} else {
learn <- data
test <- NULL
}
# Get copula data (u-scale) and marginal densities from the learning (and optional test) sets
copula_data <- get_u_data_dens(learn=learn, test=test, total_cl = total_classes, var_types= var_types)
# Extract necessary components
learn_u <- copula_data$train_u
dmar_learn <- copula_data$dmar_train
print(summary(learn_u))
test_u <- if (!is.null(test)) copula_data$test_u else NULL
dmar_test <- if (!is.null(test)) copula_data$dmar_test else NULL
# Fit vine copulas for each class and compute learning posterior probabilities
vine_fit <- vine_all(
learn = learn_u,
vars = vars,
total_cl = total_classes,
dmar_learn = dmar_learn,
copfam = copfam,
nCore = nCore,
var_types = var_types
)
# Retrieve posterior probabilities for the learning data
post_prob_learn <- vine_fit$post_prob_learn
# Compute posterior probabilities for the test set (if it exists)
if (!is.null(test_u)) {
post_prob_test <- vine_out(test_u, dmar_test, total_classes, vine_fit$chosen_cand, vine_fit$vine)$post_prob
} else {
post_prob_test <- NULL
}
# Return final results
list(
vine = vine_fit$vine,
chosen_vars = vine_fit$chosen_cand,
fitted_kdes = copula_data$margins,
post_prob_learn = post_prob_learn,
post_prob_test = post_prob_test,
train_data = learn,
test_data = test
)
}
vineclass(data = data, var_types = c("c", "d"))
#' df_splitted <- split_data(df, 0.8)
#' df_train <- df_splitted$train
#' df_test <- df_splitted$test
#' copuladata <- get_u_data_dens(learn=df_train, test=df_test, total_cl=2, var_types= c("c", "c", "c"))
#' vinefit <- vine_all(copuladata$train_u, 1:3, 2, copuladata$dmar_train,"parametric", 1, c("c", "c", "c"))
#' }
#'
#' @import rvinecopulib
#' @importFrom parallel mclapply
#' @noRd
vine_all <- function(learn, vars, total_cl, dmar_learn, copfam, nCore, var_types) {
cols <- ncol(learn[[1]])
vine_mdl <- list()
nvars <- length(var_types)
disc_vine <- list()
# Identify discrete variables and their positions
is_d <- var_types[vars] == "d"
d_indices <- vars[is_d]
d_positions <- which(var_types == "d")
indices <- match(d_indices, d_positions)
# Combine selected variables with discrete variable indices
if (length(is_d) > 0) {
chosen_cand <- c(vars, nvars + indices)
} else {
chosen_cand <- vars
}
# Fit vine models with discrete handling
if (any(var_types == "d") && length(nvars) > 2) {
for (k in 1:total_cl) {
input_df <- learn[[k]][which(learn[[k]][, cols] == k), vars]
n1 <- nrow(input_df)
rr1 <- vWcor(input_df, var_types[vars])
disc_vine[[k]] <- GaussVineMST(rr1, n1, 1.01)$VineA[1:length(vars), length(vars):1]
}
vine_mdl <- parallel::mclapply(1:total_cl, function(k) {
vinecop(
learn[[k]][which(learn[[k]][, cols] == k), chosen_cand],
presel = FALSE,
structure = disc_vine[[k]],
family_set = copfam,
var_types = var_types[vars]
)
}, mc.cores = nCore)
} else {
print("here")
print(summary(learn[[k]]))
vine_mdl <- parallel::mclapply(1:total_cl, function(k) {
vinecop(
learn[[k]][which(learn[[k]][, cols] == k), chosen_cand],
presel = FALSE,
family_set = copfam,
var_types = var_types[vars]
)
}, mc.cores = nCore)
}
# Compute densities and posterior probabilities
dvine_learn <- sapply(1:total_cl, function(j) {
result <- dvinecop(learn[[j]][, chosen_cand], vine_mdl[[j]])
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
lik_points_learn <- sapply(1:total_cl, function(j) {
result <- apply(dmar_learn[[j]][, vars], 1, prod) * dvine_learn[, j]
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
lik_per_obs_learn <- apply(lik_points_learn, 1, sum)
post_prob_learn <- lik_points_learn / rep(lik_per_obs_learn, each = total_cl)
list(
vine = vine_mdl,
chosen_cand = vars,
post_prob_learn = post_prob_learn
)
}
vineclass(data = data, var_types = c("c", "d"))
#' df_splitted <- split_data(df, 0.8)
#' df_train <- df_splitted$train
#' df_test <- df_splitted$test
#' copuladata <- get_u_data_dens(learn=df_train, test=df_test, total_cl=2, var_types= c("c", "c", "c"))
#' vinefit <- vine_all(copuladata$train_u, 1:3, 2, copuladata$dmar_train,"parametric", 1, c("c", "c", "c"))
#' }
#'
#' @import rvinecopulib
#' @importFrom parallel mclapply
#' @noRd
vine_all <- function(learn, vars, total_cl, dmar_learn, copfam, nCore, var_types) {
cols <- ncol(learn[[1]])
vine_mdl <- list()
nvars <- length(var_types)
disc_vine <- list()
# Identify discrete variables and their positions
is_d <- var_types[vars] == "d"
d_indices <- vars[is_d]
d_positions <- which(var_types == "d")
indices <- match(d_indices, d_positions)
# Combine selected variables with discrete variable indices
if (length(is_d) > 0) {
chosen_cand <- c(vars, nvars + indices)
} else {
chosen_cand <- vars
}
# Fit vine models with discrete handling
if (any(var_types == "d") && length(nvars) > 2) {
for (k in 1:total_cl) {
input_df <- learn[[k]][which(learn[[k]][, cols] == k), vars]
n1 <- nrow(input_df)
rr1 <- vWcor(input_df, var_types[vars])
disc_vine[[k]] <- GaussVineMST(rr1, n1, 1.01)$VineA[1:length(vars), length(vars):1]
}
vine_mdl <- parallel::mclapply(1:total_cl, function(k) {
vinecop(
learn[[k]][which(learn[[k]][, cols] == k), chosen_cand],
presel = FALSE,
structure = disc_vine[[k]],
family_set = copfam,
var_types = var_types[vars]
)
}, mc.cores = nCore)
} else {
print("here")
print(summary(learn[[1]]))
vine_mdl <- parallel::mclapply(1:total_cl, function(k) {
vinecop(
learn[[k]][which(learn[[k]][, cols] == k), chosen_cand],
presel = FALSE,
family_set = copfam,
var_types = var_types[vars]
)
}, mc.cores = nCore)
}
# Compute densities and posterior probabilities
dvine_learn <- sapply(1:total_cl, function(j) {
result <- dvinecop(learn[[j]][, chosen_cand], vine_mdl[[j]])
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
lik_points_learn <- sapply(1:total_cl, function(j) {
result <- apply(dmar_learn[[j]][, vars], 1, prod) * dvine_learn[, j]
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
lik_per_obs_learn <- apply(lik_points_learn, 1, sum)
post_prob_learn <- lik_points_learn / rep(lik_per_obs_learn, each = total_cl)
list(
vine = vine_mdl,
chosen_cand = vars,
post_prob_learn = post_prob_learn
)
}
vineclass(data = data, var_types = c("c", "d"))
#'
#' @return A list containing:
#' \itemize{
#' \item \code{vine_lbl}: A vector containing the predicted class labels for each observation.
#' \item \code{post_prob}: A data frame of posterior probabilities with dimensions
#' \code{n_observations x total_cl}.
#' }
#'
#'
#' @noRd
vine_out <- function(test, dmar_test, total_cl, chosen_cand, vine_mdl) {
# Validate inputs
stopifnot(is.list(test), is.list(dmar_test), is.list(vine_mdl))
stopifnot(length(test) == total_cl, length(dmar_test) == total_cl, length(vine_mdl) == total_cl)
stopifnot(is.numeric(chosen_cand) && all(chosen_cand > 0))
# Compute R-vine densities for each class
rvine_densities <- sapply(seq_len(total_cl), function(j) {
result <- dvinecop(test[[j]][, chosen_cand], vine_mdl[[j]])
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
# Compute likelihood points for each class
lik_points_test <- sapply(seq_len(total_cl), function(j) {
result <- apply(dmar_test[[j]][, chosen_cand], 1, prod) * rvine_densities[, j]
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
# Compute posterior probabilities
lik_per_obs_test <- rowSums(lik_points_test)
post_prob <- lik_points_test / matrix(rep(lik_per_obs_test, total_cl), ncol = total_cl, byrow = FALSE)
# Determine predicted class labels
vine_lbl <- apply(post_prob, 1, function(x) which.max(x))
# Return results
list(vine_lbl = vine_lbl, post_prob = as.data.frame(post_prob))
}
#'
#' @return A list containing:
#' \itemize{
#' \item \code{vine_lbl}: A vector containing the predicted class labels for each observation.
#' \item \code{post_prob}: A data frame of posterior probabilities with dimensions
#' \code{n_observations x total_cl}.
#' }
#'
#'
#' @noRd
vine_out <- function(test, dmar_test, total_cl, chosen_cand, vine_mdl) {
# Validate inputs
stopifnot(is.list(test), is.list(dmar_test), is.list(vine_mdl))
stopifnot(length(test) == total_cl, length(dmar_test) == total_cl, length(vine_mdl) == total_cl)
stopifnot(is.numeric(chosen_cand) && all(chosen_cand > 0))
print("out")
print(chosen_cand)
print(head(test[[2]]))
# Compute R-vine densities for each class
rvine_densities <- sapply(seq_len(total_cl), function(j) {
result <- dvinecop(test[[j]][, chosen_cand], vine_mdl[[j]])
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
# Compute likelihood points for each class
lik_points_test <- sapply(seq_len(total_cl), function(j) {
result <- apply(dmar_test[[j]][, chosen_cand], 1, prod) * rvine_densities[, j]
result[is.na(result)] <- 1e-5
result[result == 0] <- 1e-5
result
})
# Compute posterior probabilities
lik_per_obs_test <- rowSums(lik_points_test)
post_prob <- lik_points_test / matrix(rep(lik_per_obs_test, total_cl), ncol = total_cl, byrow = FALSE)
# Determine predicted class labels
vine_lbl <- apply(post_prob, 1, function(x) which.max(x))
# Return results
list(vine_lbl = vine_lbl, post_prob = as.data.frame(post_prob))
}
vineclass(data = data, var_types = c("c", "d"))
devtools::document()
set.seed(1)
n <- 1000
c1_dist <- bicop_dist("frank", 0,ktau_to_par("frank", 0.5))
c2_dist <- bicop_dist("gumbel", 0,ktau_to_par("gumbel", 0.9))
c1_u <- rbicop(n, c1_dist)
c2_u <- rbicop(n, c2_dist)
mu1 <- -1.5
mu2 <- 0
muy <- 0
lambda_y <- 2
muy <- lambda_y
sigma12<- 1
c1_obs_x <- qnorm(c1_u[,1], mu1, sigma12)
c1_obs_y <- qpois(c1_u[,2], lambda = lambda_y)
c2_obs_x <- qnorm(c2_u[,1], mu2, sigma12)
c2_obs_y <- qpois(c2_u[,2], lambda = lambda_y)
data <- data.frame(
obs_x = c(c1_obs_x, c2_obs_x),
obs_y = c(c1_obs_y, c2_obs_y),
class = c(rep(1, n), rep(2, n))
)
xx <- get_u_data_dens(data, total_cl = 2, var_types = c("c", "d"))
vineclass(data = data, var_types = c("c", "d"))
devtools::document()
devtools::document()
usethis::use_roxygen_md()
devtools::document()
set.seed(1)
n <- 1000
c1_dist <- bicop_dist("frank", 0,ktau_to_par("frank", 0.5))
c2_dist <- bicop_dist("gumbel", 0,ktau_to_par("gumbel", 0.9))
c1_u <- rbicop(n, c1_dist)
c2_u <- rbicop(n, c2_dist)
mu1 <- -1.5
mu2 <- 0
muy <- 0
lambda_y <- 2
muy <- lambda_y
sigma12<- 1
c1_obs_x <- qnorm(c1_u[,1], mu1, sigma12)
c1_obs_y <- qpois(c1_u[,2], lambda = lambda_y)
c2_obs_x <- qnorm(c2_u[,1], mu2, sigma12)
c2_obs_y <- qpois(c2_u[,2], lambda = lambda_y)
data <- data.frame(
obs_x = c(c1_obs_x, c2_obs_x),
obs_y = c(c1_obs_y, c2_obs_y),
class = c(rep(1, n), rep(2, n))
)
#xx <- get_u_data_dens(data, total_cl = 2, var_types = c("c", "d"))
vineclass(data = data, var_types = c("c", "d"))
#xx <- get_u_data_dens(data, total_cl = 2, var_types = c("c", "d"))
kk <- vineclass(data = data, var_types = c("c", "d"))
res <- kk
res2 <- cbind.data.frame(res$post_prob_test$post_prob, res$test_data$class)
res$post_prob_test$post_prob
res2 <- cbind.data.frame(res$post_prob_learn, res$train_data$class)
res2 <- cbind.data.frame(res$post_prob_test, res$test_data$class)
predicted_class <- apply(res2[, 1:2], 1, function(x) which.max(x))
# 2. Compare the predicted class with the true class
true_class <- res$test_data$class
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
load("/Users/ozgesahin/surfdrive - Özge Şahin@surfdrive.surf.nl/Surfdrive-TUD/Research/vineclassifier/genrecleanTransform.RData")
df <- subset(music2a, genre=="Classical"| genre=="Hip-Hop")
nsample <- 500*n_class
df <- df[sample(1:nrow(df), nsample), ]
df$mode <-as.numeric(as.factor(music[sample(1:nrow(df), nsample),]$mode))
n_class <- 2
df <- subset(music2a, genre=="Classical"| genre=="Hip-Hop")
nsample <- 500*n_class
df <- df[sample(1:nrow(df), nsample), ]
df$mode <-as.numeric(as.factor(music[sample(1:nrow(df), nsample),]$mode))
n_cols <- ncol(df)
df <- df[c(1:(n_cols-2), n_cols, n_cols-1)]
df[,ncol(df)] <- as.character(df[,ncol(df)])
names(df)[ncol(df)] <- "class"
df$class <- as.numeric(as.factor(df$class))
res <- vineclass(data=df, var_types = c(rep("c", ncol(df)-2), "d"))
res$chosen_vars
#res <- kk
res2 <- cbind.data.frame(res$post_prob_learn, res$train_data$class)
res2 <- cbind.data.frame(res$post_prob_test, res$test_data$class)
predicted_class <- apply(res2[, 1:2], 1, function(x) which.max(x))
# 2. Compare the predicted class with the true class
true_class <- res$test_data$class
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
load("/Users/ozgesahin/surfdrive - Özge Şahin@surfdrive.surf.nl/Surfdrive-TUD/Research/Healthcare/vineclassifier-healthcare/ERAS-all.RData")
View(insample_patpreintra_24)
df <-cbind.data.frame(insample_patpreintra_24, insample_24$ifanycomp)
View(df)
df <-cbind.data.frame(insample_patpreintra_24, insample_24$ifanycomp)
c(rep("c", "d","c", rep("d", 23), "c" , "c" , rep("d", 4))
c("c", "d","c", rep("d", 23), "c" , "c" , rep("d", 4))
res <- vineclass(data=df, var_types = c("c", "d","c", rep("d", 23), "c" , "c" , rep("d", 4)))
res$chosen_vars
#res <- kk
res2 <- cbind.data.frame(res$post_prob_learn, res$train_data$class)
res$post_prob_learn
res$train_data$class
res$train_data$`insample_24$ifanycomp`
#res <- kk
res2 <- cbind.data.frame(res$post_prob_learn, res$train_data$`insample_24$ifanycomp`)
predicted_class <- apply(res2[, 1:2], 1, function(x) which.max(x))
# 2. Compare the predicted class with the true class
true_class <- res$test_data$class
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
# 2. Compare the predicted class with the true class
true_class <- insample_24$ifanycomp
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
predicted_class
true_class
# 2. Compare the predicted class with the true class
true_class <- res$test_data$class+1
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
true_class
# 2. Compare the predicted class with the true class
true_class <- res$test_data$class+1
# 2. Compare the predicted class with the true class
true_class <- insample_24$ifanycomp+1
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
true_class
predicted_class
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
unique(true_class)
which(true_class == class)
predicted_class
# 3. Compute misclassification rate for each class
misclassification_rate <- sapply(unique(true_class), function(class) {
# Find the indices for the current class
class_indices <- which(true_class == class)
# Calculate the number of misclassifications for this class
misclassifications <- sum(predicted_class[class_indices] != class)
# Return the misclassification rate (misclassifications / total in class)
misclassifications / length(class_indices)
})
# Print the misclassification rate for each class
print(misclassification_rate)
devtools::document()
devtools::build()
devtools::document()
devtools::build()
devtools::document()
devtools::document()
pkgload::dev_help('test_vineclass')
devtools::document()
library(knitr)
knit("README.Rmd", output = "README.md")
getwd()
knit("README.Rmd", output = "README.md")
library(knitr)
knit("README.Rmd", output = "README.md")
knit("README.Rmd", output = "README.md")
