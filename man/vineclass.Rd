% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vineclass_train.R
\name{vineclass}
\alias{vineclass}
\title{Vine copula-based classifiers}
\usage{
vineclass(
  data,
  vars = NULL,
  learn_ratio = 1,
  copfam = "parametric",
  nCore = NULL,
  trunc_lvl = Inf,
  var_types
)
}
\arguments{
\item{data}{A data frame or matrix. The last column should contain class labels,
which will be re-labeled internally to 1, 2, ..., K if not already.}

\item{vars}{A vector of integer indices specifying which columns (excluding the class label)
are used for modeling. If missing or \code{NULL}, all variables except the last (class label)
are used.}

\item{learn_ratio}{A numeric value in \eqn{(0,1]} specifying the proportion of data for learning.
If \code{learn_ratio = 1}, all data is used for learning (no test set, default).}

\item{copfam}{A character vector specifying the pair copula families (e.g., "parametric", "nonparametric").}

\item{nCore}{A positive integer specifying the number of cores to use for parallel computations.
If missing or \code{NULL}, it is set to the minimum of the total number of classes and
\code{parallel::detectCores() - 1}.}

\item{trunc_lvl}{A numeric value specifying the truncation level for the vine copula models. Inf means no truncation}

\item{var_types}{A character vector of length \code{ncol(data) - 1}, indicating "c" or "d" for each variable.}
}
\value{
A list containing:
\describe{
\item{\code{vine}}{List of fitted vine copula models for each class.}
\item{\code{chosen_vars}}{Vector of selected variables used for vine modeling.}
\item{\code{fitted_kdes}}{List of KDEs (marginal densities) for each class in the learning set.}
\item{\code{post_prob_learn}}{Posterior probabilities for the learning data.}
\item{\code{post_prob_test}}{Posterior probabilities for the test data (if a test set exists).}
\item{\code{test_data}}{Data frame containing the test data used for evaluation (if a test set exists).}
}
}
\description{
This is the main function for vine copula-based classification. It splits the
data into learning and test sets (if applicable), fits vine copula models for each class,
and returns posterior probabilities for both the learning and test sets.
}
\examples{
\donttest{
set.seed(123)
data <- data.frame(matrix(rnorm(1000), ncol = 5))
data$class <- sample(1:2, nrow(data), replace = TRUE)

# Run vine-based classification using 80\% of the data for learning
result <- vineclass(
  data=data,
  learn_ratio = 0.8,
  copfam = "parametric",
  trunc_lvl = Inf,
  var_types = c("c", "c", "c", "c","c")
)
head(result$post_prob_learn)
head(result$post_prob_test)
}

}
\references{
Sahin O and Joe H (2024), Vine Copula-Based Classifiers with Applications.
Journal of Classification, 1-29.

Brechmann E C and Joe H (2015), Truncation of vine copulas using fit indices.
Journal of Multivariate Analysis, 138, 19-33.
}
